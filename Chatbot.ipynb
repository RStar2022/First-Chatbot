{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skB6rUEpgQfG",
        "outputId": "70bd0a49-4ec7-4de6-b796-cc468a9dad10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ABqb7zRgVbQ",
        "outputId": "ff36e2d1-6692-486f-ad95-2ecca1478a9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZXLES-MgX3f",
        "outputId": "b34f2ff4-e798-444f-d4e0-7b63daf4de03"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1kivOgDmjzn",
        "outputId": "33013ea4-24e9-4142-f55a-a1182af92deb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.9/dist-packages (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiGQyYIjgMC8",
        "outputId": "772ef685-cba4-44ed-ab0f-5869cc41d422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "\"ChatBot\"\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#Download NLTK data\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "#Load data\n",
        "import json\n",
        "#f = open(\"/home/user/Downloads/intents.json\")\n",
        "f = open(\"intents.json\")\n",
        "data = json.load(f)\n",
        "\n",
        "#Preprocess data\n",
        "import string\n",
        "words=[]\n",
        "classes=[]\n",
        "data_x=[]\n",
        "data_y = []\n",
        "ignore_words=[\"!\",\"?\"]\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        #Tokenize data\n",
        "        tokens = nltk.word_tokenize(pattern) #tokenize each pattern\n",
        "        words.extend(tokens) #and append tokens and words\n",
        "\n",
        "        data_x.append(pattern) #appending pattern to data_x\n",
        "        data_y.append(intent[\"tag\"]) #appending the associated tag to each pattern\n",
        "\n",
        "        if intent[\"tag\"] not in classes :\n",
        "          classes.append(intent[\"tag\"])\n",
        "\n",
        "# initializing lemmetizer to get stem words       \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#lemmatize all words in the vocab and convert them to lowercase\n",
        "#if the words don't appear in punctuation\n",
        "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
        "#sorting the vocab and classes in alphabetical order and taking the # set to ensure no duplication error\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))\n",
        "print(len(classes)*[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this step convert text into numbers using the bag of words model\n",
        "# Create an array of number of size the same as the length of vocabulary lists.\n",
        "# Array = 1 if word is in pattern/tag being read(data_x) and 0 if absent\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "#Text to Numbers\n",
        "training = []\n",
        "out_empty = [0] * len(classes)\n",
        "# creating the bag of words model\n",
        "for idx, doc in enumerate(data_x):\n",
        "  bow = []\n",
        "  text = lemmatizer.lemmatize(doc.lower())\n",
        "  for word in words :\n",
        "    bow.append(1) if word in text else bow.append(0)\n",
        "    \n",
        "    #mark the index of class that the current pattern is associated to\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(data_y[idx])]=1\n",
        "\n",
        "    #add the one hot encoded Bow and associated classes to training\n",
        "    training.append([bow, output_row])\n",
        "\n",
        "#shuffle the data and convert it to an array\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype = object)\n",
        "#split the features and target labels\n",
        "train_x = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))"
      ],
      "metadata": {
        "id": "J2gwWL-jrXws"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ruHGOkpHhAYZ",
        "outputId": "fb346c86-4a8a-4186-cc6b-115b5bf335c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-cpu\n",
            "  Downloading tensorflow_cpu-2.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (3.20.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (0.4.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (23.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (2.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (67.7.2)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (2.12.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (1.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (1.22.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (2.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (1.54.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (0.32.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (23.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (4.5.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-cpu) (16.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow-cpu) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow-cpu) (0.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-cpu) (2.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-cpu) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-cpu) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-cpu) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-cpu) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-cpu) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-cpu) (0.7.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-cpu) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-cpu) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-cpu) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-cpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-cpu) (6.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-cpu) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-cpu) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-cpu) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-cpu) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-cpu) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-cpu) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-cpu) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-cpu) (3.2.2)\n",
            "Installing collected packages: tensorflow-cpu\n",
            "Successfully installed tensorflow-cpu-2.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),),activation =\"relu\"))\n",
        "model.add(Dropout(0,5))\n",
        "model.add(Dense(64, activation =\"relu\"))\n",
        "model.add(Dropout(0,5))\n",
        "model.add(Dense(len(train_y[0]), activation = \"softmax\"))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.01, weight_decay = 1e-6)\n",
        "model.compile(loss =\"categorical_crossentropy\",\n",
        "              optimizer = adam,\n",
        "              metrics = [\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit(x = train_x, y = train_y, epochs = 200, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajT4G8Rv2W5w",
        "outputId": "90315647-588b-4624-b539-a99b48b18792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 128)               33536     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 38)                2470      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,262\n",
            "Trainable params: 44,262\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "3304/3304 [==============================] - 19s 5ms/step - loss: 0.0306 - accuracy: 0.9913\n",
            "Epoch 2/200\n",
            "3304/3304 [==============================] - 15s 4ms/step - loss: 0.0184 - accuracy: 0.9947\n",
            "Epoch 3/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0038 - accuracy: 0.9975\n",
            "Epoch 4/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0158 - accuracy: 0.9958\n",
            "Epoch 5/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0036 - accuracy: 0.9974\n",
            "Epoch 6/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9979\n",
            "Epoch 7/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0036 - accuracy: 0.9975\n",
            "Epoch 8/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 9/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 10/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 11/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 12/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 13/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 14/200\n",
            "3304/3304 [==============================] - 12s 3ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 15/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 16/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 17/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 18/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 19/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 20/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 21/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 22/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 23/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 24/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 25/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9972\n",
            "Epoch 26/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 27/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 28/200\n",
            "3304/3304 [==============================] - 12s 3ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 29/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 30/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9977\n",
            "Epoch 31/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 32/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0193 - accuracy: 0.9965\n",
            "Epoch 33/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 34/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 35/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 36/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 37/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 38/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 39/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 40/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 41/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0049 - accuracy: 0.9974\n",
            "Epoch 42/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0223 - accuracy: 0.9969\n",
            "Epoch 43/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 44/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 45/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 46/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 47/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 48/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 49/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 50/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 51/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 52/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 53/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 54/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 55/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 56/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 57/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 58/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 59/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 60/200\n",
            "3304/3304 [==============================] - 14s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 61/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 62/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 63/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 64/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 65/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0144 - accuracy: 0.9971\n",
            "Epoch 66/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9978\n",
            "Epoch 67/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 68/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 69/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 70/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 71/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 72/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 73/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 74/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 75/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 76/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 77/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 78/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 79/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 80/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 81/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 82/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 83/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 84/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 85/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 86/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 87/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 88/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 89/200\n",
            "3304/3304 [==============================] - 12s 3ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 90/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 91/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 92/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 93/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9975\n",
            "Epoch 94/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 95/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 96/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 97/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 98/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 99/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 100/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 101/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9975\n",
            "Epoch 102/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 103/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 104/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 105/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 106/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 107/200\n",
            "3304/3304 [==============================] - 14s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 108/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 109/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 110/200\n",
            "3304/3304 [==============================] - 12s 3ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 111/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 112/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 113/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 114/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 115/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 116/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 117/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 118/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 119/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0036 - accuracy: 0.9975\n",
            "Epoch 120/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 121/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9978\n",
            "Epoch 122/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 123/200\n",
            "3304/3304 [==============================] - 12s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 124/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 125/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 126/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 127/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 128/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9975\n",
            "Epoch 129/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 130/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 131/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 132/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 133/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 134/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 135/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 136/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 137/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 138/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 139/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 140/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 141/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 142/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 143/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 144/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 145/200\n",
            "3304/3304 [==============================] - 12s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 146/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 147/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 148/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 149/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 150/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9976\n",
            "Epoch 151/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 152/200\n",
            "3304/3304 [==============================] - 11s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 153/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 154/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 155/200\n",
            "3304/3304 [==============================] - 14s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 156/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 157/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 158/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 159/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Epoch 160/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 161/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9973\n",
            "Epoch 162/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 163/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 164/200\n",
            "3304/3304 [==============================] - 13s 4ms/step - loss: 0.0035 - accuracy: 0.9974\n",
            "Epoch 165/200\n",
            "3304/3304 [==============================] - 12s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 166/200\n",
            " 627/3304 [====>.........................] - ETA: 10s - loss: 0.0043 - accuracy: 0.9969"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the Input\n",
        "def clean_text(text):\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "\"\"\"\"Receives text(string) as an input and then tokenizes using word_tokenize\n",
        "Each token is then converted into ist lemmatizer.\n",
        "\"\"\"\n",
        "\n",
        "def bag_of_words(text, vocab):\n",
        "  tokens = clean_text(text)\n",
        "  bow = [0] * len(vocab)\n",
        "  for w in tokens :\n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w :\n",
        "        bow[idx] = 1\n",
        "  return np.array(bow)\n",
        "\n",
        "\"\"\"Calls clean text func, converts the text into an array using the \n",
        "bow model using the input vocabulary, then return the same arrays\"\"\"\n",
        "\n",
        "def pred_class(text, vocab, labels):\n",
        "  bow = bag_of_words(text,vocab)\n",
        "  result = model.predict(np.array([bow]))[0] #Extracting probabilities\n",
        "  print(result)\n",
        "  thresh = 0.5\n",
        "  y_pred = [[indx, res] for indx, res in enumerate(result) if res> thresh]\n",
        "  y_pred.sort(key = lambda x : x[1], reverse = True) #sort values of probability in decreasing order\n",
        "  return_list = []\n",
        "  for r in y_pred :\n",
        "    print(r)\n",
        "    return_list.append(labels[r[0]]) #Contains labels(tags) for highest probability\n",
        "  return return_list\n",
        "  print(return_list)\n",
        "\n",
        "\"\"\"\n",
        "Takes text, vocab, and labels as input and returns a list that contains a tag\n",
        "corresponding to the highest probability\n",
        "\"\"\"\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "  if len(intents_list) == 0 :\n",
        "    result = \"sorry! I don't understand\"\n",
        "  else :\n",
        "    tag = intents_list[0]\n",
        "    list_of_intents = intents_json[\"intents\"]\n",
        "    for i in list_of_intents :\n",
        "      if i[\"tag\"] == tag :\n",
        "        result = random.choice(i[\"responses\"])\n",
        "        break\n",
        "  return result\n",
        "\n",
        "  \"\"\"\n",
        "  Takes the tag returned by previous func and uses it to randomly chocose a response\n",
        "  corresponding to the same tag in intent.json.\n",
        "  And if inten_list is empty, that is when the prob dont cross the threshold and will pas string \"Sorry\" \n",
        "  as ChatBot's response\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "3rY-S6F592rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interacting with chatbot\n",
        "print(\"Press 0 if you don't want to chat with our Chatbot\")\n",
        "while True :\n",
        "  message = input(\"\")\n",
        "  if message == \"0\" :\n",
        "    break\n",
        "  intents = pred_class(message,words,classes)\n",
        "  result = get_response(intents, data)\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "H2e1fYiQjh2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics =[\"accuracy\"])\n",
        "\n",
        "#Train model\n",
        "num_epochs = 50\n",
        "history = model.fit(training_data, training_labels, epochs = num_epochs, verbose =2)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def predict_answer(model,tokenizer, question):\n",
        "    #Preprocess question\n",
        "    question = preprocess(question)\n",
        "    #convert question to sequence\n",
        "    sequence = tokenizer.texts_to_sequences([question])\n",
        "    #Pad sequence\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding = padding_type, truncating = trunc_type)\n",
        "    #Predict answer \n",
        "    pred = model.predict(padded_sequence)[0]\n",
        "    #Get index of highest probability\n",
        "    idx = np.argmax(pred)\n",
        "    #Get answer\n",
        "    answer = tokenizer.index_word[idx]\n",
        "    return answer\n",
        "\n",
        "#Start chatbot\n",
        "while True :\n",
        "    question = input(\"You: \")\n",
        "    answer = predict_answer(model, tokenizer, question)\n",
        "    print(\"Chatbot :\", answer)"
      ],
      "metadata": {
        "id": "kOQaePreglja"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}